model_parameters:
  model_name: "meta-llama/Llama-3.2-1B-Instruct"
  # dtype: "float16"
  compile: false
  model_parallel: false
  batch_size: 1
  multichoice_continuations_start_space: null # If true/false, will force multiple choice continuations to start/not start with a space. If none, will do nothing
  use_chat_template: true
  generation_parameters:
    temperature: 0.6
    top_p: 0.9